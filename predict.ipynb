{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/archive/master.zip\" to C:\\Users\\irisc/.cache\\torch\\hub\\master.zip\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1    229245  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7276605 parameters, 7276605 gradients\n",
      "\n",
      "YOLOv5  856dbff torch 1.8.0+cu111 CUDA:0 (GeForce GTX 1050, 4096.0MB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding autoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path_or_model='yolov5s.pt',force_reload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affect(boxes, width):\n",
    "    distances = []\n",
    "    if len(boxes)==0:\n",
    "        return []\n",
    "    for box in boxes:\n",
    "        d = abs((box[2]+box[0])/2.-width/2.)\n",
    "        if d == 0:\n",
    "            d = 1\n",
    "        distances.append(d)\n",
    "    affect_index_1 = distances.index(min(distances))\n",
    "    if len(distances)==1:\n",
    "        return [True]\n",
    "    distances_new = distances.copy()\n",
    "    distances_new[affect_index_1]=2000\n",
    "    affect_index_2 = distances.index(min(distances_new))\n",
    "    if boxes[affect_index_1][3]>=boxes[affect_index_2][3] and distances[affect_index_2]/distances[affect_index_1]<=1.5:\n",
    "        affect_index = affect_index_2\n",
    "    else:\n",
    "        affect_index = affect_index_1\n",
    "    affect_array = []\n",
    "    for i in range(len(distances)):\n",
    "        if i == affect_index:\n",
    "            affect_array.append(True)\n",
    "        else:\n",
    "            affect_array.append(False)\n",
    "    return affect_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolation(dict_predict, frame_width, frame_height):\n",
    "    interpolated_predict = copy.deepcopy(dict_predict)\n",
    "    \n",
    "    # время выполнения без интерполяции 508 ms\n",
    "    # пересчет координат после всего\n",
    "    \n",
    "    # словарь для каждого светофора с координатами каждые 20 кадров\n",
    "    # {id_1: [[coords_1, frame number_1, id in dict_predictions_1 (j)],\n",
    "    #       [coords_2, frame number_2, id in dict_predictions_2 (j)]],\n",
    "    #  id_2: [[coords_1, frame number_1, id in dict_predictions_1 (j)],\n",
    "    #       [coords_2, frame number_2, id in dict_predictions_2 (j)]]}\n",
    "    dict_key_points = {}\n",
    "    \n",
    "    # хранит координаты светофоров предудыщего кадра, если светофор отсутствует в новом кадре, то эти координаты записываются\n",
    "    # в список соответствующего светофора в dict_key_points\n",
    "    curr_points = {}\n",
    "    \n",
    "    # словарь хранит последовательность индексов j для каждого светофора на случай, если в каждом кадре он имеет разые индексы\n",
    "    # это позволит не вычислять при пересчете координат \n",
    "    dict_j = {}\n",
    "    \n",
    "    frame_numbers = list(map(str,sorted(list(map(int,interpolated_predict.keys())))))\n",
    "    \n",
    "    next_id = 0\n",
    "    for frame_number in frame_numbers:\n",
    "        updated_tl = set()\n",
    "        new_tl = set()\n",
    "        for key in interpolated_predict[frame_number].keys():\n",
    "            box = interpolated_predict[frame_number][key]\n",
    "            coord = box['coords']\n",
    "            old_point = False\n",
    "            if coord[0]<=2 or coord[2]<=2 or coord[1]>=frame_width-2 or coord[3]>=frame_height-2:\n",
    "                continue\n",
    "            cx = (coord[0]+coord[2])/2.\n",
    "            cy = (coord[1]+coord[3])/2.\n",
    "            \n",
    "            # обновление текущих точек\n",
    "            for point_key in curr_points.keys():\n",
    "                if curr_points[point_key][2]>cx and curr_points[point_key][0]<cx and curr_points[point_key][3]>cy and curr_points[point_key][1]<cy and int(frame_number)-int(curr_points[point_key][4])<=10:\n",
    "                    old_point = True\n",
    "                    curr_points[point_key] = [coord[0], coord[1], coord[2], coord[3], frame_number]                            \n",
    "                    dict_j[point_key][frame_number] = key\n",
    "                    updated_tl.add(point_key)\n",
    "            \n",
    "            # если данный бокс новый, то old_point останется False, тогда нужно добавить в curr_points с новым id.\n",
    "            if old_point == False:\n",
    "                curr_points[next_id] = [coord[0], coord[1], coord[2], coord[3], frame_number]\n",
    "                dict_key_points[next_id] = []\n",
    "                dict_j[next_id] = {}\n",
    "                dict_j[next_id][frame_number] = key\n",
    "                updated_tl.add(next_id)\n",
    "                new_tl.add(next_id)\n",
    "                next_id+=1\n",
    "            \n",
    "        # проверка на необновленные боксы\n",
    "        # если бокс не обновлен, то добавляеся в dict_key_points\n",
    "        first_last_boxes = list(set(curr_points.keys())-updated_tl)\n",
    "        for key in first_last_boxes:\n",
    "            if int(frame_number) - int(curr_points[key][4])>10:\n",
    "                dict_key_points[key].append(curr_points[key])\n",
    "                curr_points.pop(key)\n",
    "            \n",
    "        for key in list(new_tl): \n",
    "            dict_key_points[key].append(curr_points[key])\n",
    "            \n",
    "        # теперь запись оставшихся боксов в dict_key_points, если кадр 30-ый\n",
    "        if int(frame_number)%30==0:\n",
    "            for key in list(set(curr_points.keys()-new_tl)):\n",
    "                dict_key_points[key].append(curr_points[key])\n",
    "    # перезапись боксов в dict_predictions\n",
    "    for key in dict_key_points.keys():\n",
    "        # key - номер светофора\n",
    "        key_boxes = dict_key_points[key]\n",
    "            \n",
    "        start_width = key_boxes[0][2]-key_boxes[0][0]\n",
    "        start_height = key_boxes[0][3]-key_boxes[0][1]\n",
    "        \n",
    "        if int(key_boxes[-1][4])-int(key_boxes[0][4])<2:\n",
    "            for kb in range(len(key_boxes)):\n",
    "                if key_boxes[kb][4] in interpolated_predict.keys():\n",
    "                    if dict_j[key][key_boxes[kb][4]] in interpolated_predict[key_boxes[kb][4]].keys():\n",
    "                        interpolated_predict[key_boxes[kb][4]].pop(dict_j[key][key_boxes[kb][4]])\n",
    "                        if len(interpolated_predict[key_boxes[kb][4]])==0:\n",
    "                            interpolated_predict.pop(key_boxes[kb][4])\n",
    "            continue\n",
    "        \n",
    "        for kb in range(len(key_boxes)-1):\n",
    "            \n",
    "            if 2*(int(key_boxes[kb+1][4])-int(key_boxes[kb][4]))==0:\n",
    "                side_change = 1        \n",
    "            else:\n",
    "                area_start = (key_boxes[kb][2]-key_boxes[kb][0])*(key_boxes[kb][3]-key_boxes[kb][1])\n",
    "                area_end = (key_boxes[kb+1][2]-key_boxes[kb+1][0])*(key_boxes[kb+1][3]-key_boxes[kb+1][1])\n",
    "                side_change = (area_end/area_start)**(1/(2*(int(key_boxes[kb+1][4])-int(key_boxes[kb][4]))))\n",
    "            \n",
    "            \n",
    "            frame_count = int(key_boxes[kb+1][4])-int(key_boxes[kb][4])\n",
    "            if frame_count == 0:\n",
    "                continue\n",
    "            # покадровое изменение каждой координаты светофора\n",
    "            dx = ((key_boxes[kb+1][2]+key_boxes[kb+1][0])/2-(key_boxes[kb][2]+key_boxes[kb][0])/2)/frame_count\n",
    "            dy = ((key_boxes[kb+1][3]+key_boxes[kb+1][1])/2-(key_boxes[kb][3]+key_boxes[kb][1])/2)/frame_count\n",
    "            \n",
    "            start_cx = (key_boxes[kb][2]+key_boxes[kb][0])/2\n",
    "            start_cy = (key_boxes[kb][3]+key_boxes[kb][1])/2\n",
    "            \n",
    "            width = key_boxes[kb][2]-key_boxes[kb][0]\n",
    "            height = start_height*(width/start_width)\n",
    "            \n",
    "            frame_number = int(key_boxes[kb][4])\n",
    "            for i in range(frame_count):\n",
    "                new_x_left = (start_cx + dx*i)-(width*(side_change**i))/2\n",
    "                new_y_left = (start_cy + dy*i)-(height*(side_change**i))/2\n",
    "                new_x_right = (start_cx + dx*i)+(width*(side_change**i))/2\n",
    "                new_y_right = (start_cy + dy*i)+(height*(side_change**i))/2\n",
    "                if len(interpolated_predict[str(frame_number+i)])>0:\n",
    "                    if str(frame_number+i) in dict_j[key].keys():\n",
    "                        interpolated_predict[str(frame_number+i)][dict_j[key][str(frame_number+i)]]['coords']=[int(new_x_left), int(new_y_left), int(new_x_right), int(new_y_right)]\n",
    "                    else:\n",
    "                        max_key = max(list(map(int,list(interpolated_predict[str(frame_number+i)].keys()))))\n",
    "                        interpolated_predict[str(frame_number+i)][str(max_key+1)] = copy.deepcopy(interpolated_predict[str(frame_number+i-1)][dict_j[key][str(frame_number+i-1)]])\n",
    "                        interpolated_predict[str(frame_number+i)][str(max_key+1)]['coords']=[int(new_x_left), int(new_y_left), int(new_x_right), int(new_y_right)]\n",
    "                        dict_j[key][str(frame_number+i)] = str(max_key+1)\n",
    "                else:\n",
    "                    interpolated_predict[str(frame_number+i)]['0'] = copy.deepcopy(interpolated_predict[str(frame_number+i-1)][dict_j[key][str(frame_number+i-1)]])\n",
    "                    interpolated_predict[str(frame_number+i)]['0']['coords']=[int(new_x_left), int(new_y_left), int(new_x_right), int(new_y_right)]\n",
    "                    dict_j[key][str(frame_number+i)] = '0'\n",
    "            \n",
    "            if kb == len(key_boxes)-2:\n",
    "                frame_number = str(key_boxes[kb+1][4])\n",
    "                new_x_left = (start_cx + dx*frame_count)-(width*(side_change**frame_count))/2\n",
    "                new_y_left = (start_cy + dy*frame_count)-(height*(side_change**frame_count))/2\n",
    "                new_x_right = (start_cx + dx*frame_count)+(width*(side_change**frame_count))/2\n",
    "                new_y_right = (start_cy + dy*frame_count)+(height*(side_change**frame_count))/2\n",
    "                interpolated_predict[frame_number][dict_j[key][frame_number]]['coords']=[int(new_x_left), int(new_y_left), int(new_x_right), int(new_y_right)]\n",
    "    # расчет affect\n",
    "    for frame in interpolated_predict.keys():\n",
    "        box_keys = list(interpolated_predict[frame].keys())\n",
    "        boxes = []\n",
    "        affect_keys = []\n",
    "        for box_key in box_keys:\n",
    "            if interpolated_predict[frame][box_key]['state'] != \"unknown\":\n",
    "                boxes.append(interpolated_predict[frame][box_key]['coords'])\n",
    "                affect_keys.append(box_key)\n",
    "            else:\n",
    "                interpolated_predict[frame][box_key]['affect']= False\n",
    "        affect_list = affect(boxes, frame_width)\n",
    "        for i, box_key in enumerate(affect_keys):\n",
    "            interpolated_predict[frame][box_key]['affect'] = affect_list[i]\n",
    "    \n",
    "    return interpolated_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_similarity(prev_image, curr_image, boxes):\n",
    "    prev = cv.cvtColor(prev_image, cv.COLOR_BGR2GRAY)\n",
    "    curr = cv.cvtColor(curr_image, cv.COLOR_BGR2GRAY)\n",
    "    for box in boxes:\n",
    "\n",
    "        cropped_current_image = curr[box[1]:box[3],box[0]:box[2]]\n",
    "        cropped_previous_image = prev[box[1]:box[3],box[0]:box[2]]\n",
    "\n",
    "        cropped_current_image_norm = cropped_current_image/255.\n",
    "        cropped_previous_image_norm = cropped_previous_image/255.\n",
    "\n",
    "        similarity_rate = abs(np.sum(cropped_current_image_norm-cropped_previous_image_norm)/((box[2]-box[0])*(box[3]-box[1])))\n",
    "        \n",
    "        if similarity_rate<0.04:\n",
    "            continue\n",
    "        else:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_predict(path, json_path, model, device):\n",
    "    \n",
    "    #path - путь к видео\n",
    "    #json_path - путь, где сохранится json файл в формате \"folder(если нужна папка)/file_name.txt\"\n",
    "    #model - модель\n",
    "    #device - видеокарта\n",
    "    \n",
    "    cap = cv.VideoCapture(path) # Вывод с видео файла\n",
    "    frame_width  = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "    dict_predictions = {}\n",
    "#     model.to(device)\n",
    "    model.eval()\n",
    "    i=1\n",
    "    colors = {2: \"red\", 1: \"yellow\", 0: \"green\", 3: \"unknown\"}\n",
    "    image_previous = None\n",
    "    boxes_previous = None\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if i%2==0:\n",
    "            dict_predictions[str(i)] = copy.deepcopy(dict_predictions[str(i-1)])\n",
    "            i+=1\n",
    "            continue\n",
    "        #определение похожести \n",
    "        if (image_previous is not None) and (boxes_previous is not None):\n",
    "            similar = check_similarity(image_previous, frame, boxes_previous)\n",
    "            if similar:\n",
    "                dict_predictions[str(i)] = copy.deepcopy(dict_predictions[str(i-1)])\n",
    "                i+=1\n",
    "                continue\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            image_previous = frame.copy()\n",
    "            frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "            \n",
    "            prediction = model([frame], size = frame_width)\n",
    "            dict_predictions[str(i)]={}\n",
    "\n",
    "            boxes = prediction.xyxy[0].cpu().numpy().astype('int')\n",
    "            \n",
    "            boxes = np.array([box for box in boxes if box[-1]==9]) #беру только 9 класс, это светофоры\n",
    "            \n",
    "            if len(boxes)>0:\n",
    "                boxes_previous = boxes.copy()\n",
    "            else:\n",
    "                boxes_previous = None\n",
    "            \n",
    "            for j, box in enumerate(boxes):\n",
    "                dict_predictions[str(i)][str(j)] = {}\n",
    "                curr_box = [int(box[0]), int(box[1]), int(box[2]), int(box[3])]\n",
    "\n",
    "                dict_predictions[str(i)][str(j)][\"coords\"] = curr_box\n",
    "\n",
    "                color = box[-1]\n",
    "                if color not in colors.keys():\n",
    "                    dict_predictions[str(i)][str(j)][\"state\"] = \"unknown\"\n",
    "                else:\n",
    "                    dict_predictions[str(i)][str(j)][\"state\"] = copy.deepcopy(colors[color])\n",
    "\n",
    "        i+=1\n",
    "    \n",
    "    final_predictions = interpolation(dict_predictions, frame_width, frame_height)\n",
    "    \n",
    "    with open(json_path, 'w') as outfile:\n",
    "        json.dump(final_predictions, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "video_predict(\"phase_1/video_3.MP4\", \"phase_1/video_3.txt\", model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_display(source_video_path, target_video, vid_boxes, fps = 24):\n",
    "    cap = cv.VideoCapture(source_video_path)\n",
    "    width  = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "    i=1\n",
    "    out = cv.VideoWriter(target_video,cv.VideoWriter_fourcc(*'DIVX'), fps, (width, height))\n",
    "    with open(vid_boxes) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        boxes = []\n",
    "        colors = []\n",
    "        affects = []\n",
    "        if str(i) in data.keys():\n",
    "            for j in data[str(i)].keys():\n",
    "                box = data[str(i)][j][\"coords\"]\n",
    "                boxes.append(list(map(int, box)))\n",
    "                state = data[str(i)][j][\"state\"]\n",
    "                if state == 'red':\n",
    "                    colors.append((0,0,255))\n",
    "                if state == 'yellow':\n",
    "                    colors.append((0,255,255))\n",
    "                if state == 'green':\n",
    "                    colors.append((0,255,0))\n",
    "                if state == 'unknown':\n",
    "                    colors.append((255,255,255))\n",
    "                affects.append(data[str(i)][j][\"affect\"])\n",
    "            \n",
    "        for box, color, affect in zip(boxes, colors, affects):\n",
    "            \n",
    "            cv.rectangle(frame, (box[2], box[3]), (box[0], box[1]), color, 2)\n",
    "            if affect == True:\n",
    "                text_color = tuple([90 if c==255 else c for c in color])\n",
    "                frame = cv.putText(frame, 'affect', (box[0], box[3]+20), fontFace = cv.FONT_HERSHEY_SIMPLEX,\n",
    "                                   fontScale = 0.6, thickness = 2, color = text_color)\n",
    "\n",
    "        out.write(frame)\n",
    "        i += 1\n",
    "        \n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_display(\"phase_1/video_3.MP4\", \"phase_1/video_3_boxes_model_half.MP4\", \"phase_1/video_3.txt\", fps = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
