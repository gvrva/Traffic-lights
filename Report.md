# Предсказание и постобработка

## Описание процесса предсказания

Для предсказания на пользовательских видео необходимо подключить модель predict.py с помощью 
```python
import predict
```
Таким образом можно использовать функции из этого модуля. Модель yolo для полученных весов строится с помощью команды
```python
model = torch.hub.load('ultralytics/yolov5', 'custom', 'path_to_weight_file', force_reload=True)
```
где вместо path_to_weight_file указывается путь к файлу .pt с весами модели.

Предсказание светофоров на видео существляется с помощью основной функции video_predict из модуля predict.py и связанных с ней функций, осуществляющих постобработку результатов детекции нейросетью YOLOv5l.

С помощью библиотеки opencv видео покадрово считывается и передается в нейросеть. На выходе получаем массив с координатами ограничивающих прямоугольников, значением confidence (коэффициент "уверенности" нейросети в предсказаниях) и классом, которые означает сигнал светофора.

Предсказанные нейросетью ограничивающие прямоугольники и сигналы светофоров записываются в словарь, где ключ - номер кадра, значение - словарь обнаруженных светофоров с уникальным id, координатами верхнего левого и правого нижнего углов bounding box'ов и состояния светофров. В этот словарь не попадают детектированные объекты, для которых значение confidence нейросети мало.

Составленный для всех кадров словарь передается на постобработку результатов с помощью функции interpolate() из модуля predict.py. данная функция производит "сглаживание" траектории движения светофора на видео и изменения размера его bounding box'а. 

После преобразования координат для каждого кадра определяется светофор, который влияет на движение машины. Такому светофору ставится значение True для ключа "affect", если светофор не влияет, то записывается False.

Итоговые результаты детекции записываются в .json файл с заданным пользователем названием.

## Алгоритмы используемых функций

### video_predict()

Функция покадрово считывает видео и для каждого кадра определяет bounding box'ы, сигналы светофоров и их влияние на полосу.
Для ускорения предсказания в нейросеть подается только каждый второй кадр, для пропущенного кадра копируются результаты предыдущей детекции. Также для последующих кадров вычисляется коэффициент похожести изображений в области предсказанных ранее ограничивающих прямоугольников. Если новый кадр определяется, как похожий с последним переданным в нейросеть кадром (значение метрики меньше 0.02), то для данного кадра копируются предыдущие результаты детекции. Опеределение схожести изображений осуществляется функцией check_similarity() из модуля predict.py
Полученные результаты передаются в функцию interpolation(), а затем записываются в указанный пользователем файл.
**Статистика предсказаний для видеокарты Tesla P100-PCIE-16GB**
| Видео       |Длительность видео мин:сек  | Время предсказания |
| ------------|:------------------:| -----:|
| Video_0     | 00:40 | 00:14 |
| Video_1     | 00:40 | 00:24 |
| Video_2     | 00:40 | 00:11 |
| Video_3     | 02:10 | 02:15 |
| Video_4     | 00:35 | 00:47 |
| Video_5     | 00:40 | 00:27 |

### check_similarity()

Данная функция вычисляет метрику похожести изображений в области bounding box'ов.
Полученные на вход 2 изображения переводятся в одноканальный (черно-белый) формат.
Для каждой области bounding box'а целые значения цвета переводятся в область значений [0,1]. После этого вычисляется разность изображений и находится среднее значение этой разности, которая и является знаечнием метрики. Данная метрика соответствует первой норме.
Если для каждого box'а значение полученной метрики меньше 0.02, то изменения в текущем изображении считаются незначительными и возвращается знаечние True (изображения практически одинаковые). В таком случае для текущего изображения копируется предыдущее предсказание. Если же хотя бы для одного box'а значение метрики больше или равно 0.02, то возвращается False (ищображения различаются) и для данного кадра box'ы предсказываются нейросетью.

### interpolation()

На вход этой функции подается словарь с полученными для каждого кадра предсказаниями, который используется для отслеживания светофоров на видео.
dict_key_points хранит данные о первой и последней детекции каждого светофора под уникальным ключом.
dict_j хранит ключ отслеженного светофора в полученном на входе словаре для каждого кадра по порядку.
После заполнения словаря отслеживание для каждого свеофора вычисляются новые кооординаты на основе предыдущих координат этого светофора. Новые координаты вычисляются путем усреднения изменения координат на предыдущих 30 (максимум) кадрах. Новые координаты определяются относительно i-30 кадра, где i номер текущего кадра.
После вычисления новых координат для каждого кадра вычисляется влияющий светофор с помощью функции affect.
Чтобы снизить количество появления ложноположительных влияний устанавливается пауза в 30 кадров. Это значит, что при смене цвета влияющего светофора на i-ом кадре, на текущем кадре и всех кадрах до i+30 все светофоры будут признаны affect False. Если предыдущий цвет светофора являлся affect True дольше 30 кадров, то пауза устанавливается в 15 кадров, так как в таком случае смена цвета может означать верное определение affect, в таком случае пауза в 15 кадров не повлияет на результаты метрики, определяющей верность окончательных предсказаний. Если смена цвета произошла на том же светофоре, то пауза не устанавливается и обновляются переменные отслеживания.

### affect()

Данная функция принимает на вход box'ы и ширину кадра.
Вычисляется площадь каждого светофора и отсеиваются те светофоры, площадь которых меньше максимальной площади минимум в 4 раза. Это позволяет отсеить далекие светофоры. которые точно не влияют на движение в текущий момент. Таким светофорам автоматически присваивается расстояние до середины (учитывается только ширина) кадра 2000.
Для оставшихся светофоров расстояние кадра равно истинному растоянию до середины. Данный критерий был выбран, так как на большинстве тестируемых видео влияющий светофор оказывался ближе всего к центру.
Из светофоров выбираются два ближайших к центру.Пусть первый светофор ближе к центру. Если первый светофор оказывается ниже второго и при этом расстояние между ними достаточно мало, то влияющим светофором выбирается второй. Если хотя бы одно из условий не выполнется, то влияющим выбирается первый. Такой дополнительный критерий позовляет выбрать действительно влияющий светофор в случае, если для дальнего светофора предсказывается bounding box значительно больше его размера.
Функция возвращает список значений True и False соответственно исходному порядку светофоров. affect True всегда может быть не более олного светофора.


# Воспроизведение видео с предсказанными box'ами

Воспроизведение видео происходит с помощью функции video_display() из модуля predict.py. Эта функции принимает в качестве параметров путь к исходному видео, путь к видео с box'ами, путь к json файлу с предсказаниями.
Функция покадрово считывает исходное видео, отрисовывает на нем получившиеся ограничивающие прямоугольники цвета сигнала свеофора и подписывает влияющий светофор с помощью надписи affect под этим светофором. Получившийся кадр добавляется к выходному видео.
После результатов на всех кадрах, получившиеся картинки собираются в выходное видео, заданного формата и с частотой кадров, котоая равна частоте кадров исходного видео.


# Итоги
Полученная нейросеть и допонительный функции позволяют достаточно хорошо произвести детекцию светофоров, определить их сигнал и влияние на движение машины. Безусловно, полученные результаты неидеальны. Для лучшей работы нейросети требуется больше данных, особенно для редких видов светофоров и для желтого сигнала свеофора, так как таких примеров оказалось мало даже с применением аугментаций. Алгоритмы постобработки результатов также можно значительно улучшить, если провести анализ на выявление более сложных закономерностей и установление оптимальных гиперпараметров.
Полученные результаты и алгоритмы достаточно хорошо выполняют поставленную задачу и могут являться основой для разработки более сложных систем.
