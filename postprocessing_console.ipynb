{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affect(boxes, height, width):\n",
    "    distances = []\n",
    "    areas = []\n",
    "    for box in boxes:\n",
    "        areas.append((box[3]*width)*(box[4]*height))\n",
    "    max_area = max(areas)\n",
    "    for i, area in enumerate(areas):\n",
    "        if max_area/area>=3:\n",
    "            areas[i]=0\n",
    "            distances.append(1000)\n",
    "        else:\n",
    "            d = abs(boxes[i][1]-0.5)\n",
    "            distances.append(d)\n",
    "    affect_index = distances.index(min(distances))\n",
    "    affect_array = []\n",
    "    for i in range(len(distances)):\n",
    "        if i == affect_index:\n",
    "            affect_array.append(True)\n",
    "        else:\n",
    "            affect_array.append(False)\n",
    "    return affect_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#без сглаживания\n",
    "def txt_to_json(video_name, path_to_txt, path_to_video, json_path):\n",
    "    \n",
    "    #video_name - имя текущего видео\n",
    "    #path_to_txt - путь, где хранится txt файлы после yolo, в цонце должен быть обратный слеш, например,'labels/'\n",
    "    #path_to_video - путь к исходному видео\n",
    "    #json_path - путь и имя файла, где сохранится json\n",
    "\n",
    "    cap = cv.VideoCapture(path_to_video) # Вывод с видео файла\n",
    "    frame_width  = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "    print(frame_width, frame_height)\n",
    "\n",
    "    all_txt = list(sorted(os.listdir(path_to_txt)))\n",
    "    txt = [t for t in all_txt if video_name in t]\n",
    "    dict_predictions = {}\n",
    "    colors = {2: \"red\", 1: \"yellow\", 0: \"green\"}\n",
    "\n",
    "    for t in txt:\n",
    "        i = int(t[len(video_name)+1:-4])\n",
    "        if path_to_txt[-1] == '/':\n",
    "            file_name = path_to_txt+t\n",
    "        else:\n",
    "            file_name = path_to_txt+'/'+t\n",
    "        with open(file_name) as f:\n",
    "            boxes = f.readlines()\n",
    "\n",
    "            boxes = np.array([list(map(float,box[:-1].split())) for box in boxes])\n",
    "\n",
    "            affect_list = affect(boxes, frame_height, frame_width)\n",
    "            dict_predictions[i] = []\n",
    "            for j, box in enumerate(boxes):\n",
    "                box[0] = int(box[0])\n",
    "\n",
    "                width = box[3]*frame_width\n",
    "                height = box[4]*frame_height\n",
    "\n",
    "                x_left = box[1]*frame_width-width/2\n",
    "                y_left = box[2]*frame_height-height/2\n",
    "                x_right = box[1]*frame_width+width/2\n",
    "                y_right = box[2]*frame_height+height/2\n",
    "\n",
    "                dict_predictions[i].append({j:{}})\n",
    "                curr_box = list(map(str,[int(x_left), int(y_left), int(x_right), int(y_right)]))\n",
    "\n",
    "                dict_predictions[i][j][j][\"coords\"] = curr_box\n",
    "\n",
    "                color = box[0]\n",
    "                if color not in colors.keys():\n",
    "                    dict_predictions[i][j][j][\"state\"] = \"unknown\"\n",
    "                else:\n",
    "                    dict_predictions[i][j][j][\"state\"] = colors[color]\n",
    "\n",
    "                dict_predictions[i][j][j][\"affect\"] = str(affect_list[j])\n",
    "    with open(json_path, 'w') as outfile:\n",
    "        json.dump(dict_predictions, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_display(source_video_path, target_video, vid_boxes, fps = 24):\n",
    "    cap = cv.VideoCapture(source_video_path)\n",
    "    width  = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "    i=0\n",
    "    out = cv.VideoWriter(target_video,cv.VideoWriter_fourcc(*'DIVX'), fps, (width, height))\n",
    "    with open(vid_boxes) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        boxes = []\n",
    "        colors = []\n",
    "        affects = []\n",
    "        if str(i) in data.keys():\n",
    "            for j, tl_dict in enumerate(data[str(i)]):\n",
    "                box = tl_dict[str(j)][\"coords\"]\n",
    "                boxes.append(list(map(int, box)))\n",
    "                state = tl_dict[str(j)][\"state\"]\n",
    "                if state == 'red':\n",
    "                    colors.append((0,0,255))\n",
    "                if state == 'yellow':\n",
    "                    colors.append((0,255,255))\n",
    "                if state == 'green':\n",
    "                    colors.append((0,255,0))\n",
    "                if state == 'unknown':\n",
    "                    colors.append((255,255,255))\n",
    "                affects.append(tl_dict[str(j)][\"affect\"])\n",
    "            \n",
    "        for box, color, affect in zip(boxes, colors, affects):\n",
    "            \n",
    "            cv.rectangle(frame, (box[2], box[3]), (box[0], box[1]), color, 2)\n",
    "            if affect == 'True':\n",
    "                frame = cv.putText(frame, 'affect', (box[0], box[3]+20), fontFace = cv.FONT_HERSHEY_SIMPLEX,\n",
    "                                   fontScale = 0.5, thickness = 1, color = color)\n",
    "\n",
    "        out.write(frame)\n",
    "        i += 1\n",
    "        \n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример использования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_to_json('video_3', 'labels/', 'phase_1/video_3.MP4', 'video_3_json.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_display(\"phase_1/video_3.MP4\", \"phase_1/video_3_boxes.MP4\", \"video_3_json.txt\", fps = 24)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
